{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Results Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pyprojroot import here\n",
        "sys.path.insert(0, str(here()))\n",
        "from src.utils import get_pooled_df\n",
        "from src.data import get_fold_from_disk, DECODED_LABELS\n",
        "from collections import Counter\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ead23a13",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 0: macro_f1=0.2523\n",
            "Fold 1: macro_f1=0.2523\n",
            "Fold 2: macro_f1=0.2523\n",
            "Fold 3: macro_f1=0.2535\n",
            "Fold 4: macro_f1=0.2555\n",
            "\n",
            "Majority-class baseline: 0.2532 ± 0.0012\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   downplays     0.0000    0.0000    0.0000        22\n",
            "        same     0.6212    1.0000    0.7664        82\n",
            " exaggerates     0.0000    0.0000    0.0000        28\n",
            "\n",
            "    accuracy                         0.6212       132\n",
            "   macro avg     0.2071    0.3333    0.2555       132\n",
            "weighted avg     0.3859    0.6212    0.4761       132\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jubacochran/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
            "/home/jubacochran/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
            "/home/jubacochran/miniforge3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        }
      ],
      "source": [
        "full_df = get_pooled_df()\n",
        "\n",
        "f1_scores = []\n",
        "for fold in range(5):\n",
        "    train_fold, val_fold = get_fold_from_disk(full_df, fold=fold, k=5, seed=7)\n",
        "\n",
        "    majority_label = Counter(train_fold[\"exaggeration_label\"]).most_common(1)[0][0]\n",
        "    y_true = val_fold[\"exaggeration_label\"]\n",
        "    y_pred = [majority_label] * len(y_true)\n",
        "\n",
        "    macro_f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
        "    f1_scores.append(macro_f1)\n",
        "    print(f\"Fold {fold}: macro_f1={macro_f1:.4f}\")\n",
        "\n",
        "print(f\"\\nMajority-class baseline: {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\")\n",
        "print(classification_report(y_true, y_pred, target_names=list(DECODED_LABELS.values()), digits=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "853b7c03",
      "metadata": {},
      "source": [
        "# The base model is predicting the majority class 'same' as expected, .62 for precision and .76 F1. The average macro is .25 this shows the balance of recall and precision across all classes. The model fails to predict the other classes in any other metric. These are the metrics we can use to understand the improvement of our experimentation. The standard deviation of macro scores across all the folds is 0.0012. Since the variance is this significantly low and the mass is centered around this very tight point we can have confidence that the baseline performance is consistent. This matters because we have significant imbalance in our dataset and we're using a crossfold validation technique. "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
